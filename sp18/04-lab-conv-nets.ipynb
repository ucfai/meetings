{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencies for Python3 Kernel (RUN THIS TO VIEW IFRAME VISUALIZATIONS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:34:03.116137Z",
     "start_time": "2018-03-08T20:34:03.113190Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, SVG, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T22:59:52.566331Z",
     "start_time": "2018-03-08T22:59:52.528178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmpdh6imvnc.c:3:43: fatal error: /data/darknet/include/darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "//C kernel test\n",
    "#include <stdio.h>\n",
    "#include \"/darknet/src/darknet.h\"\n",
    "\n",
    "void main(){printf(\"hello\");}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolving a Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time object detection and classification with YOLO\n",
    "\n",
    "**What you'll learn:** \n",
    "- How a Convolutional Neural Network is implemented in a real world application\n",
    "- How to build convolutional and (max)pooling layers in C\n",
    "- Run and configure YOLO. (And, if you follow the CUDA/OpenCV installation, run YOLO in real-time with your webcam!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Terminal from Jupyter; then copy-paste:\n",
    "\n",
    "```\n",
    "curl https://pjreddie.com/media/files/yolo.weights -o /notebooks/sp18/data/darknet/yolo.weights --create-dirs\n",
    "```\n",
    "\n",
    "This will download a pre-trained YOLO into your darknet directory. By the time we run it, the weights should be finished downloading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Learn what you're working with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Darknet is an elegant neural network framework that can build anything from traditional to recurrent to convolutional to long short-term memory (LSTM) neural networks. For this workshop, we will be focusing on running YOLO by rebuilding functions for the convolutional and pooling layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, we have to understand the Darknet's architecture. Otherwise, we're just grasping at straws! Below is the abstract structure for a layer. I removed variables that are not in the scope of the workshop to avoid confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T22:39:30.257690Z",
     "start_time": "2018-03-08T22:39:30.233866Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp6hab6t_b.c:1:37: fatal error: darknet/include/darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include \"/darknet/src/darknet.h\"\n",
    "struct layer_ex{\n",
    "    LAYER_TYPE type;\n",
    "    ACTIVATION activation;\n",
    "    COST_TYPE cost_type;\n",
    "    void (*forward)   (struct layer, struct network); //Forward propagation\n",
    "    void (*backward)  (struct layer, struct network); //Backward propagation\n",
    "    void (*update)    (struct layer, update_args);    //updater\n",
    "    void (*forward_gpu)   (struct layer, struct network);\n",
    "    void (*backward_gpu)  (struct layer, struct network);\n",
    "    void (*update_gpu)    (struct layer, update_args);\n",
    "    \n",
    "    int batch_normalize; //boolean -> use batch normalization == 1. There were other normalization methods but we use this\n",
    "    int batch; // # of samples to be fed in\n",
    "    \n",
    "                //vvvv We manipulate these as matrices, but physically, they are 1D arrays w/ calloc\n",
    "    int inputs;    //data fed into the layer\n",
    "    int outputs;   //data pushed out of the layer\n",
    "    int nweights;  // # of weights \n",
    "                //^^^^\n",
    "    int nbiases;    //Additional weights to add\n",
    "\n",
    "    int h,w,c;  //height h and width w of each input 'matrix', and a count c of all the matrices fed in\n",
    "    int out_h, out_w, out_c;  //height h and width w of each output 'matrix', and a count c of all the matrices returned\n",
    "    int n;    //similar to out_c, but it's used for creating the layer\n",
    "    \n",
    "    int groups;     //An AlexNet adaption to the convolutional layer. Partitions the kernel (filters)\n",
    "    int size;       //rank of a given input matrix ()\n",
    "    int side;\n",
    "    int stride; //How many columns over the kernel (filter matrix) moves\n",
    "\n",
    "    float temperature;\n",
    "    float probability;\n",
    "    float scale;        //Scale weights with this\n",
    "\n",
    "\n",
    "    float * biases;      //Memory location for biases we will be considering in the convolutional layer\n",
    "    float * bias_updates;\n",
    "\n",
    "    float * scales;       //Memory location for scales for the weights\n",
    "    float * scale_updates;\n",
    "\n",
    "    float * weights;      //Memory location for weights\n",
    "    float * weight_updates;\n",
    "\n",
    "    float * delta;\n",
    "    float * output;\n",
    "    float * squared;\n",
    "    float * norms;\n",
    "    \n",
    "    \n",
    "//VVVVVVVVVVVVVVVVVVVVVVVVVVVVv\n",
    "    float * spatial_mean;\n",
    "    float * mean;\n",
    "    float * variance;\n",
    "//                                          Variables for Batch Normalization\n",
    "    float * mean_delta; \n",
    "    float * variance_delta;\n",
    "\n",
    "    float * rolling_mean;\n",
    "    float * rolling_variance;\n",
    "\n",
    "    float * x;\n",
    "    float * x_norm;\n",
    "//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "    \n",
    "    /*CUT GPU STUFF FOR EXAMPLES...*/\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Breaking down the ConvNet pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ConvNet is a series of Convolutional and pooling layers appended to a (usually) fully connected neural network (or ANN.) These layers are needed in order to maintain spatial relations between pixels in an image, something that ANNs are unable to do. Our last workshop went over how to program an ANN from scratch. We now want to show how we can add these additional layers to our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/images/CNN_pipeline.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: For each convolutional layer, we must denote the dimensions of the input. Our inputs will strictly be images, so we have width **w** and height **h** of the input matrix. Since we read the data in as one big array, we partition the array into equal sizes. **c** is the count, as in, how many different matrices we will be reading in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter (kernel) performs element-wise matrix multiplication in every position that the filter fully \"fits\" within the input matrix. The filter moves column by column and row by row w.r.t its **stride** (e.g. stride of 2 will move the filter two rows/columns at a time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:31:53.918386Z",
     "start_time": "2018-03-08T20:31:53.905074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"assets/cnns/convolution.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f88d8724278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"assets/cnns/convolution.html\", \"1000\", \"500\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:06:34.436619Z",
     "start_time": "2018-03-08T20:06:34.408607Z"
    }
   },
   "source": [
    "**IMPORANT NOTE:** In Darknet, our filters have an additional property: **groups**\n",
    "\n",
    "What is a group?? Well, let's compare convolution with and without the use of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional Convolutional Layers vs. Group Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a traditional convolution looks something like this. Given a set of samples (left), we apply our filters (middle) to create a set of feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/cnns/convlayer_traditional.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **groups**, we essentially partition the filters, which allows the convolutional layer to categorize filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/cnns/convlayer_group.svg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this into consideration, we will develop a function to create a convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:36:30.213161Z",
     "start_time": "2018-03-08T20:36:30.184415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /darknet/src/convolutional_layer.h:4:0,\n",
      "                 from /tmp/tmpdpyh0hbn.c:2:\n",
      "/darknet/src/cuda.h:4:21: fatal error: darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include \"/darknet/src/darknet.h\"\n",
    "#include \"/darknet/src/convolutional_layer.h\"\n",
    "\n",
    "convolutional_layer make_convolutional_layer_ex(int batch, int h, int w, int c, int n, int groups, int size, int stride, int padding, ACTIVATION activation, int batch_normalize, int binary, int xnor, int adam)\n",
    "{\n",
    "    \n",
    "//////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "//Create weights and scales for the weights with respect to Muller Transform\n",
    "\n",
    "    float scale = sqrt(2./(size*size*c/l.groups));\n",
    "    for(i = 0; i < l.nweights; ++i) l.weights[i] = scale*rand_normal();\n",
    "    \n",
    "    //Calculate the dimensions of the output matrix with this ~~~MAGIC~~~ function! \n",
    "    int out_w = convolutional_out_width(l);\n",
    "    int out_h = convolutional_out_height(l);\n",
    "    \n",
    "  \n",
    "//////////////////////////////////////////////////\n",
    "    //Batch Normalization\n",
    "\n",
    "    l.scales = calloc(n, sizeof(float));\n",
    "    l.scale_updates = calloc(n, sizeof(float));\n",
    "        for(i = 0; i < n; ++i){\n",
    "            l.scales[i] = 1;\n",
    "        }\n",
    "\n",
    "    l.mean = calloc(n, sizeof(float));\n",
    "    l.variance = calloc(n, sizeof(float));\n",
    "\n",
    "    l.mean_delta = calloc(n, sizeof(float));\n",
    "    l.variance_delta = calloc(n, sizeof(float));\n",
    "\n",
    "    l.rolling_mean = calloc(n, sizeof(float));\n",
    "    l.rolling_variance = calloc(n, sizeof(float));\n",
    "    l.x = calloc(l.batch*l.outputs, sizeof(float));\n",
    "    l.x_norm = calloc(l.batch*l.outputs, sizeof(float));\n",
    "   \n",
    "////////////////////////////////////////////////////////\n",
    "    //NOT GOING OVER GPU SET UP\n",
    "///////////////////////////////////////////////////////\n",
    "\n",
    "    fprintf(stderr, \"conv  %5d %2d x%2d /%2d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", n, size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "\n",
    "    return l;\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set up the function to create convolutional layers, we must do the same for the pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall:** Pooling layers compress the data outputted from the convolutional layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How:** Input is sectioned into small pieces. One element is chosen from each section and is fed into a smaller, output matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will focus on **maxpooling**, which chooses the element with the highest value in each section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maxpooling visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:34:46.728603Z",
     "start_time": "2018-03-08T20:34:46.724063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"350\"\n",
       "            src=\"assets/cnns/maxpool.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd1901cb940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(\"assets/cnns/maxpool.html\", 600, 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. So now to create the maxpool layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T22:05:52.442914Z",
     "start_time": "2018-03-08T22:05:52.421081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp2ch30_we.c:1:38: fatal error: /darknet/include/darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include \"/darknet/src/darknet.h\"\n",
    "#include \"/darknet/src/maxpool_layer.h\"\n",
    "\n",
    "maxpool_layer make_maxpool_layer_ex(int batch, int h, int w, int c, int size, int stride, int padding)\n",
    "{\n",
    "    maxpool_layer l = {0};\n",
    "\n",
    "    fprintf(stderr, \"max          %d x %d / %d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "    return l;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have explained the set up of the convolutional and pooling layers, give a shot at implementing the forward / backward passes of each!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the functions integral to training our ConvNet:\n",
    "- forward_convolutional_layer() = Applies convolution onto a given convolutional layer\n",
    "\n",
    "- backward_convolutional_layer() = Applies backpropagation in a given convolutional layer, gets the rate of change of weights\n",
    "\n",
    "\n",
    "**things to keep in mind:**\n",
    " - net.workspace => allocated space for the network data. i.e. TELLS YOU WHICH LAYER YOU ARE CURRENTLY ON and ITS DATA\n",
    " - l.batch => # of samples fed into the convolutional layer per run through\n",
    " - gemm() = General Matrix Multiplication\n",
    " - the layer struct will help guide you through your development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T22:17:16.123511Z",
     "start_time": "2018-03-08T22:17:16.104228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmphd9qknim.c:1:38: fatal error: /darknet/include/darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include \"/darknet/src/darknet.h\"\n",
    "#include \"/darknet/src/convolutional_layer.h\"\n",
    "\n",
    "void main()\n",
    "{\n",
    "    convolutional_layer l = make_convolutional_layer(1, 5, 5, 3, 2, 1, 5, 2, 1, RELU, 1, 0, 0, 0);\n",
    "    l.batch_normalize = 1;\n",
    "    float data[] = {1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3};\n",
    "    net.input = data;\n",
    "    forward_convolutional_layer_student(l, net);\n",
    "    backward_convolutional_layer_student(l, net);\n",
    "}\n",
    "\n",
    "void forward_convolutional_layer_student(convolutional_layer l, network net)\n",
    "{\n",
    "    int i, j;\n",
    "\n",
    "    fill_cpu(l.outputs*l.batch, 0, l.output, 1);\n",
    "\n",
    "    if(l.xnor){\n",
    "        binarize_weights(l.weights, l.n, l.c/l.groups*l.size*l.size, l.binary_weights);\n",
    "        swap_binary(&l);\n",
    "        binarize_cpu(net.input, l.c*l.h*l.w*l.batch, l.binary_input);\n",
    "        net.input = l.binary_input;\n",
    "    }\n",
    "\n",
    "/////////////////////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "    //<><><><><><><><><><><><><><><>\n",
    "    int m = /*???/l.groups *//// size of output w.r.t the # of groups \n",
    "    int k = /*???/l.groups *////input volume size w.r.t the # of groups\n",
    "    int n = /// output area size\n",
    "\n",
    "    for(i = 0; i < /*?????*/; ++i){   //For each sample that's fed into this layer...\n",
    "        for(j = 0; j < /*?????*/; ++j){   //in case of AlexNet implementation, we must account for the groups \n",
    "            //configure the memory placement of the pointers\n",
    "            float *a = // l.???  + l.???*(j/l.groups)         Memory interval for the filter\n",
    "            float *b = // net.???                             Memory interval for current part of input\n",
    "            float *c = // l.??? + (i*l.groups + j)*?*?      Memory interval to place outputs\n",
    "\n",
    "            im2col_cpu(net.input + (i*l.groups + j)*l.c/l.groups*l.h*l.w,  \n",
    "                l.c/l.groups, l.h, l.w, l.size, l.stride, l.pad, b);   /////GIVEN\n",
    "            gemm(0,0,m,n,k,1,/*?*/,k,/*?*/,n,1,/*?*/,n); // General Matrix multiplication\n",
    "            //hint: what applies to k in convolution? what applies to n?\n",
    "        \n",
    "        }\n",
    "    }\n",
    "///////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    if(l.batch_normalize){\n",
    "        forward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        add_bias(l.output, l.biases, l.batch, l.n, l.out_h*l.out_w);\n",
    "    }\n",
    "\n",
    "    activate_array(l.output, l.outputs*l.batch, l.activation);\n",
    "    if(l.binary || l.xnor) swap_binary(&l);\n",
    "}\n",
    "\n",
    "//Backpropagation on a convolutional layer\n",
    "void backward_convolutional_layer_student(convolutional_layer l, network net)\n",
    "{\n",
    "    \n",
    "\n",
    "    int i, j;\n",
    "    //REMEMBER THAT IN BACKPROP, THE INPUT AND OUTPUT ARE SWITCHED\n",
    "    int m = /*???/l.groups *//// size of output w.r.t the # of groups \n",
    "    int k = /*???/l.groups *////input volume size w.r.t the # of groups\n",
    "    int n = /// output area size\n",
    "\n",
    "    \n",
    "    gradient_array(l.output, l.outputs*l.batch, l.activation, l.delta); //gets rate of change \n",
    "\n",
    "    if(l.batch_normalize){\n",
    "        backward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        backward_bias(l.bias_updates, l.delta, l.batch, l.n, k);\n",
    "    }\n",
    "    \n",
    "    \n",
    "////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    //<><><><><><><><><><><>\n",
    "    for(i = 0; i < /*?????*/; ++i){ //For each sample that's fed into this layer...\n",
    "        for(j = 0; j < /*?????*/; ++j){ //for each group...\n",
    "    //<><<><>><><><><><><><>\n",
    "            float *a = // l.??? + (i*l.groups + j)*?*?          Memory interval for the filter\n",
    "            float *b = // net.???                             Memory interval for current part of input\n",
    "            float *c = // l.???  + l.???*(j/l.groups)     Memory interval to place outputs\n",
    "\n",
    "            float *im = net.input+(i*l.groups + j)*l.c/l.groups*l.h*l.w;\n",
    "                \n",
    "            //GIVEN\n",
    "            im2col_cpu(im, l.c/l.groups, l.h, l.w, \n",
    "                    l.size, l.stride, l.pad, b);\n",
    "            \n",
    "            gemm(0,1,m,n,k,1,/*?*/,k,/*?*/,k,1,/*?*/,n); //hint: put into same order as in forward_convolutional_layer\n",
    "            \n",
    "            //If the change of rate is not 0. hint: remember that 0 = false in C\n",
    "            if(net./*??????*/){ //update weights.. \n",
    "                a = // l.???  + l.???*(j/l.groups) \n",
    "                b = // l.??? + (i*l.groups + j)*?*?\n",
    "                c = // net.???\n",
    "\n",
    "                gemm(1,0,n,k,m,1,/*?*/,n,/*?*/,k,0,/*?*/,k); //apply the general matrix mult\n",
    "\n",
    "                col2im_cpu(net.workspace, l.c/l.groups, l.h, l.w, l.size, l.stride, \n",
    "                    l.pad, net.delta + (i*l.groups + j)*l.c/l.groups*l.h*l.w);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "//////////////////////////////////////////////////////////////////////////////////////////\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry, maxpooling is much much simpler to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T20:45:14.468579Z",
     "start_time": "2018-03-08T20:45:14.440356Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from /darknet/src/image.h:9:0,\n",
      "                 from /darknet/src/maxpool_layer.h:4,\n",
      "                 from /tmp/tmpuc0k5fj0.c:2:\n",
      "/darknet/src/box.h:3:21: fatal error: darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include \"/darknet/src/darknet.h\"\n",
    "#include \"/darknet/src/maxpool_layer.h\"\n",
    "\n",
    "void main()\n",
    "{\n",
    "    //make_maxpool_layer(int batch, int h, int w, int c, int size, int stride, int padding)\n",
    "    maxpool_layer l = make_maxpool_layer(1, 5, 5, 3, 5, 1, 1);\n",
    "    float data[] = {1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3};\n",
    "    net.input = data;\n",
    "    forward_maxpool_layer_student(l, net);\n",
    "    backward_maxpool_layer_student(l, net);\n",
    "}\n",
    "\n",
    "\n",
    "void forward_maxpool_layer_student(const maxpool_layer l, network net)\n",
    "{\n",
    "    int b,i,j,k,m,n;\n",
    "    int w_offset = -l.pad;\n",
    "    int h_offset = -l.pad;\n",
    "\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "////////////////////////////////////////////////////////////\n",
    "    \n",
    "    for(b = 0; b < /*???*/; ++b){  //for each sample fed into layer\n",
    "        for(k = 0; k < c; ++k){   //For every slice of this sample\n",
    "            for(i = 0; i < h; ++i){ \n",
    "                for(j = 0; j < w; ++j){\n",
    "                    \n",
    "                    int out_index = j + w*(i + h*(k + c*b));\n",
    "                    \n",
    "\n",
    "                    float max = -FLT_MAX;\n",
    "                    int max_i = -1;\n",
    "                    \n",
    "                    //Find maximum value of each section of given matrix\n",
    "                    for(n = 0; n < l.size; ++n){\n",
    "                        for(m = 0; m < l.size; ++m){\n",
    "                            int cur_h = //height offset + i * l./*?????*/ + n   calculate section w.r.t it's position: \n",
    "                            int cur_w = //width  offset + i * l./*?????*/ + m   calculate section w.r.t it's position: \n",
    "                            int index = cur_w + l.w*(cur_h + l.h*(k + b*l.c)); \n",
    "                            int valid = ( (/*??*/ >= 0) && (/*??*/ < /*??*/) && (/*??*/ >= 0) && (/*??*/ < /*??*/)); //check if within bounds of input matrix\n",
    "                            float val = (valid != 0) ? net.input[index] : -FLT_MAX; //GET MAX\n",
    "                            max_i = (val > max) ? index : max_i;\n",
    "                            max   = (val > max) ? val   : max;\n",
    "                        }\n",
    "                    }\n",
    "   \n",
    "                    l.output[out_index] = //value of element taken from this section\n",
    "                    l.indexes[out_index] = //index of element taken\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "////////////////////////////////////////////////////////////////\n",
    "}\n",
    "\n",
    "void backward_maxpool_layer(const maxpool_layer l, network net)\n",
    "{\n",
    "    //our layer now has an array of indexes (beacuse of the forward pass)\n",
    "    int i;\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "//////////////////////////////////////////////////////////////////\n",
    "    //the indexes are fed into this function as a string. how large is this string?\n",
    "    for(i = 0; i < /*??? x ??? x ??? x ??*/; ++i){ \n",
    "\n",
    "        int index = //l./*???*/      pass in maximum element's index\n",
    "        net.delta[index] += //l./*??*/   rate of change of the i'th element in layer\n",
    "    }\n",
    "/////////////////////////////////////////////////////////////////\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T20:44:07.240842Z",
     "start_time": "2018-03-07T20:44:07.234969Z"
    }
   },
   "source": [
    "# 4. Run!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have finished writing our functions, let's plug them into the source code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append code to source files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In your folder viewer, go to [PATH TO THIS REPO]/meetings/darknet/src/\n",
    "2. Copy the inner code of each function and place them in the corresponding C file and function name\n",
    "    - E.g. In **convolutional_layer.c:** forward_convolutional_layer_student() **->** forward_convolutional_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open up your terminal (or Command Prompt) and **cd** to **[PATH TO THIS REPO]/meetings/darknet/**\n",
    "\n",
    "2. **make**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T21:10:43.189915Z",
     "start_time": "2018-03-08T21:10:43.165957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmpjjb1cze6.c:2:1: error: expected identifier or '(' before '.' token\n",
      " ./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg\n",
      " ^\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "//Paste this into your terminal/command prompt\n",
    "./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg\n",
    "\n",
    "\n",
    "//You can mess around with different pictures and the threshold level:\n",
    "./darknet detect cfg/yolo.cfg yolo.weights data/dog.jpg -thresh 0\n",
    "\n",
    "//And detect mutiple objects in an image:\n",
    "./darknet detect cfg/yolo.cfg yolo.weights data/horses.jpg\n",
    "\n",
    "\n",
    "//You can even detect and classify objects in real-time!\n",
    "//Follow the guide here to install cuda and OpenCV: https://pjreddie.com/darknet/install/#cuda\n",
    "// ./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yay u did it"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "github": "thedibaccle",
    "name": "Richard DiBacco"
   }
  ],
  "hide_input": false,
  "kernelspec": {
   "display_name": "C",
   "language": "c",
   "name": "c"
  },
  "language_info": {
   "file_extension": ".c",
   "mimetype": "text/plain",
   "name": "c"
  },
  "livereveal": {
   "footer": "<footer id=\"slide_foot\">\n  <div  id=\"slide_foot-brand\">\n    <span class=\"ucfsigai-brand\"></span>\n  </div>\n  <div  id=\"slide_foot-unit\">\n    <span class=\"text-gold\"> U2: </span>&nbsp;<span class=\"text-white\"> Convolutional Neural Networks </span>\n  </div>\n  <a    id=\"slide_foot-attend\" href=\"https://goo.gl/\">\n      <span class=\"text-white\"> https://goo.gl/ </span>\n  </a>\n  <div  id=\"slide_foot-date\">\n    <span class=\"text-white\"> Feb 22, 2018 </span>\n  </div>\n</footer>\n",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
