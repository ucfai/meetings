{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T03:50:49.812901Z",
     "start_time": "2018-03-07T03:50:49.808255Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, SVG, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T01:53:57.695526Z",
     "start_time": "2018-03-08T01:53:57.674829Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmpw3y1b39z.c:2:21: fatal error: darknet.h: No such file or directory\n",
      "compilation terminated.\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "#include <stdio.h>\n",
    "#include \"darknet.h\"\n",
    "\n",
    "void main(){printf(\"hello\");}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: FIND ALL HEADERS U NEED TO INCLUDE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolving a Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time object detection and classification with YOLO\n",
    "\n",
    "**What you'll learn:** \n",
    "- How a Convolutional Neural Network is implemented in a real world application\n",
    "- How to build convolutional and (max)pooling layers in C\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-08T02:07:56.355410Z",
     "start_time": "2018-03-08T02:07:56.338787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmpio5_asmt.c:2:5: error: unknown type name 'LAYER_TYPE'\n",
      "     LAYER_TYPE type;\n",
      "     ^\n",
      "/tmp/tmpio5_asmt.c:3:5: error: unknown type name 'ACTIVATION'\n",
      "     ACTIVATION activation;\n",
      "     ^\n",
      "/tmp/tmpio5_asmt.c:4:5: error: unknown type name 'COST_TYPE'\n",
      "     COST_TYPE cost_type;\n",
      "     ^\n",
      "/tmp/tmpio5_asmt.c:5:45: warning: 'struct network' declared inside parameter list\n",
      "     void (*forward)   (struct layer, struct network); //Forward propagation\n",
      "                                             ^\n",
      "/tmp/tmpio5_asmt.c:5:45: warning: its scope is only this definition or declaration, which is probably not what you want\n",
      "/tmp/tmpio5_asmt.c:6:45: warning: 'struct network' declared inside parameter list\n",
      "     void (*backward)  (struct layer, struct network); //Backward propagation\n",
      "                                             ^\n",
      "/tmp/tmpio5_asmt.c:7:38: error: unknown type name 'update_args'\n",
      "     void (*update)    (struct layer, update_args);    //updater\n",
      "                                      ^\n",
      "/tmp/tmpio5_asmt.c:8:49: warning: 'struct network' declared inside parameter list\n",
      "     void (*forward_gpu)   (struct layer, struct network);\n",
      "                                                 ^\n",
      "/tmp/tmpio5_asmt.c:9:49: warning: 'struct network' declared inside parameter list\n",
      "     void (*backward_gpu)  (struct layer, struct network);\n",
      "                                                 ^\n",
      "/tmp/tmpio5_asmt.c:10:42: error: unknown type name 'update_args'\n",
      "     void (*update_gpu)    (struct layer, update_args);\n",
      "                                          ^\n",
      "/tmp/tmpio5_asmt.c:211:5: error: unknown type name 'tree'\n",
      "     tree *softmax_tree;\n",
      "     ^\n",
      "/tmp/tmpio5_asmt.c:213:5: error: unknown type name 'size_t'\n",
      "     size_t workspace_size;\n",
      "     ^\n",
      "[C kernel] GCC exited with code 1, the executable will not be executed"
     ]
    }
   ],
   "source": [
    "struct layer{\n",
    "    LAYER_TYPE type;\n",
    "    ACTIVATION activation;\n",
    "    COST_TYPE cost_type;\n",
    "    void (*forward)   (struct layer, struct network); //Forward propagation\n",
    "    void (*backward)  (struct layer, struct network); //Backward propagation\n",
    "    void (*update)    (struct layer, update_args);    //updater\n",
    "    void (*forward_gpu)   (struct layer, struct network);\n",
    "    void (*backward_gpu)  (struct layer, struct network);\n",
    "    void (*update_gpu)    (struct layer, update_args);\n",
    "    /*\n",
    "    int batch_normalize;\n",
    "    int shortcut;\n",
    "    int forced;\n",
    "    int flipped; \n",
    "    */\n",
    "    int batch; \n",
    "                //vvvv We manipulate these as matrices, but physically, they are 1D arrays w/ calloc\n",
    "    int inputs;    //data fed into the layer\n",
    "    int outputs;   //data pushed out of the layer\n",
    "    int nweights;  // # of weights \n",
    "                //^^^^\n",
    "    int nbiases;    //Additional weights to add\n",
    "    /*\n",
    "    int extra;\n",
    "    int truths;\n",
    "    */\n",
    "    int h,w,c;  //height h and width w of each input 'matrix', and a count c of all the matrices fed in\n",
    "    int out_h, out_w, out_c;  //height h and width w of each output 'matrix', and a count c of all the matrices returned\n",
    "    int n;\n",
    "    int max_boxes;\n",
    "    int groups;     //An AlexNet adaption to the convolutional layer. Partitions the kernel (filters)\n",
    "    int size;       //rank of a given input matrix ()\n",
    "    int side;\n",
    "    int stride; //How many columns over the kernel (filter matrix) moves\n",
    "\n",
    "    float alpha;\n",
    "    float beta;\n",
    "    float kappa;\n",
    "\n",
    "    float coord_scale;\n",
    "    float object_scale;\n",
    "    float noobject_scale;\n",
    "    float mask_scale;\n",
    "    float class_scale;\n",
    "    int bias_match;\n",
    "    int random;\n",
    "    float thresh;\n",
    "    int classfix;\n",
    "    int absolute;\n",
    "\n",
    "    int onlyforward;\n",
    "    int stopbackward;\n",
    "    int dontload;\n",
    "    int dontloadscales;\n",
    "\n",
    "    float temperature;\n",
    "    float probability;\n",
    "    float scale;\n",
    "\n",
    "    char  * cweights;\n",
    "    int   * indexes;\n",
    "    int   * input_layers;\n",
    "    int   * input_sizes;\n",
    "    int   * map;\n",
    "    float * rand;\n",
    "    float * cost;\n",
    "    float * state;\n",
    "    float * prev_state;\n",
    "    float * forgot_state;\n",
    "    float * forgot_delta;\n",
    "    float * state_delta;\n",
    "    float * combine_cpu;\n",
    "    float * combine_delta_cpu;\n",
    "\n",
    "    float * concat;\n",
    "    float * concat_delta;\n",
    "\n",
    "    float * binary_weights;\n",
    "\n",
    "    float * biases;\n",
    "    float * bias_updates;\n",
    "\n",
    "    float * scales;\n",
    "    float * scale_updates;\n",
    "\n",
    "    float * weights;\n",
    "    float * weight_updates;\n",
    "\n",
    "    float * delta;\n",
    "    float * output;\n",
    "    float * squared;\n",
    "    float * norms;\n",
    "\n",
    "    float * spatial_mean;\n",
    "    float * mean;\n",
    "    float * variance;\n",
    "\n",
    "    float * mean_delta;\n",
    "    float * variance_delta;\n",
    "\n",
    "    float * rolling_mean;\n",
    "    float * rolling_variance;\n",
    "\n",
    "    float * x;\n",
    "    float * x_norm;\n",
    "\n",
    "    float * m;\n",
    "    float * v;\n",
    "    \n",
    "    float * bias_m;\n",
    "    float * bias_v;\n",
    "    float * scale_m;\n",
    "    float * scale_v;\n",
    "\n",
    "\n",
    "    float *z_cpu;\n",
    "    float *r_cpu;\n",
    "    float *h_cpu;\n",
    "    float * prev_state_cpu;\n",
    "\n",
    "    float *temp_cpu;\n",
    "    float *temp2_cpu;\n",
    "    float *temp3_cpu;\n",
    "\n",
    "    float *dh_cpu;\n",
    "    float *hh_cpu;\n",
    "    float *prev_cell_cpu;\n",
    "    float *cell_cpu;\n",
    "    float *f_cpu;\n",
    "    float *i_cpu;\n",
    "    float *g_cpu;\n",
    "    float *o_cpu;\n",
    "    float *c_cpu;\n",
    "    float *dc_cpu; \n",
    "\n",
    "    float * binary_input;\n",
    "\n",
    "    struct layer *input_layer;\n",
    "    struct layer *self_layer;\n",
    "    struct layer *output_layer;\n",
    "\n",
    "    struct layer *reset_layer;\n",
    "    struct layer *update_layer;\n",
    "    struct layer *state_layer;\n",
    "\n",
    "    struct layer *input_gate_layer;\n",
    "    struct layer *state_gate_layer;\n",
    "    struct layer *input_save_layer;\n",
    "    struct layer *state_save_layer;\n",
    "    struct layer *input_state_layer;\n",
    "    struct layer *state_state_layer;\n",
    "\n",
    "    struct layer *input_z_layer;\n",
    "    struct layer *state_z_layer;\n",
    "\n",
    "    struct layer *input_r_layer;\n",
    "    struct layer *state_r_layer;\n",
    "\n",
    "    struct layer *input_h_layer;\n",
    "    struct layer *state_h_layer;\n",
    "\t\n",
    "    struct layer *wz;\n",
    "    struct layer *uz;\n",
    "    struct layer *wr;\n",
    "    struct layer *ur;\n",
    "    struct layer *wh;\n",
    "    struct layer *uh;\n",
    "    struct layer *uo;\n",
    "    struct layer *wo;\n",
    "    struct layer *uf;\n",
    "    struct layer *wf;\n",
    "    struct layer *ui;\n",
    "    struct layer *wi;\n",
    "    struct layer *ug;\n",
    "    struct layer *wg;\n",
    "\n",
    "    tree *softmax_tree;\n",
    "\n",
    "    size_t workspace_size;\n",
    "    \n",
    "    /*CUT GPU STUFF FOR EXAMPLES...*/\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Breaking down the ConvNet pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ConvNet is a series of Convolutional and pooling layers appended to a (usually) fully connected neural network (or ANN.) These layers are needed in order to maintain spatial relations between pixels in an image, something that ANNs are unable to do. Our last workshop went over how to program an ANN from scratch. We now want to show how we can add these additional layers to our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/images/CNN_pipeline.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each convolutional layer, we must denote the dimensions of the input. Our inputs will strictly be images, so we have width **w** and height **h** of the input matrix. Since we read the data in as one big array, we partition the array into equal sizes. **c** is the count, as in, how many different matrices we want to be reading in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "Have a evaluation function that checks to see if the function they wrote is functional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "void test_convolutional_layer()\n",
    "{\n",
    "    convolutional_layer l = make_convolutional_layer(1, 5, 5, 3, 2, 1, 5, 2, 1, RELU, 1, 0, 0, 0);\n",
    "    l.batch_normalize = 1;\n",
    "    float data[] = {1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3};\n",
    "    //net.input = data;\n",
    "    //forward_convolutional_layer(l);\n",
    "}\n",
    "*/\n",
    "\n",
    "convolutional_layer make_convolutional_layer(int batch, int h, int w, int c, int n, int groups, int size, int stride, int padding, ACTIVATION activation, int batch_normalize, int binary, int xnor, int adam)\n",
    "{\n",
    "    /* WRITE\n",
    "    \n",
    "    INSTANTIATE variables\n",
    "    */\n",
    "    int i;\n",
    "    convolutional_layer l = {0};\n",
    "    l.type = CONVOLUTIONAL;\n",
    "    \n",
    "\n",
    "    l.groups = groups;   //Filter groups. This parameter tells this layer to partition it's weights by this amount\n",
    "    l.h = h;\n",
    "    l.w = w;\n",
    "    l.c = c;\n",
    "    l.n = n;\n",
    "    l.batch = batch;     //batch size\n",
    "    l.stride = stride;\n",
    "    l.size = size;\n",
    "    l.pad = padding;\n",
    "    l.batch_normalize = batch_normalize;\n",
    "\n",
    "    l.weights = calloc(c/groups*n*size*size, sizeof(float));\n",
    "    l.weight_updates = calloc(c/groups*n*size*size, sizeof(float));\n",
    "\n",
    "    l.biases = calloc(n, sizeof(float));\n",
    "    l.bias_updates = calloc(n, sizeof(float));\n",
    "\n",
    "    l.nweights = c/groups*n*size*size;\n",
    "    l.nbiases = n;\n",
    "//////////////////////////////////////////////////////////////////////////\n",
    "    \n",
    "    \n",
    "    /* EXPLAIN\n",
    "    INSTANTIATE WEIGHTS\n",
    "    \n",
    "    \n",
    "    scale = norm of all the input matrices (rank_1^2 + rank_2^2 + ... + rank_(c)^2)^1/2\n",
    "    rand_normal() = Muller transform\n",
    "    size  = rank of each input matrix within the data, but it's set as # rows of matrix\n",
    "    c     = # of matrices\n",
    "    \n",
    "    */\n",
    "\n",
    "    float scale = sqrt(2./(size*size*c/l.groups));\n",
    "    for(i = 0; i < l.nweights; ++i) l.weights[i] = scale*rand_normal();\n",
    "    \n",
    "    //Calculate the dimensions of the output matrix with this ~~~MAGIC~~~ function! \n",
    "    int out_w = convolutional_out_width(l);\n",
    "    int out_h = convolutional_out_height(l);\n",
    "///////////////////////////////////////////\n",
    "    \n",
    "    /* WRITE\n",
    "    \n",
    "    \n",
    "    \n",
    "    */\n",
    "    \n",
    "    \n",
    "    \n",
    "    l.out_h = out_h;\n",
    "    l.out_w = out_w;\n",
    "    l.out_c = n;\n",
    "    l.outputs = l.out_h * l.out_w * l.out_c;\n",
    "    l.inputs = l.w * l.h * l.c;\n",
    "\n",
    "    l.output = calloc(l.batch*l.outputs, sizeof(float));\n",
    "    l.delta  = calloc(l.batch*l.outputs, sizeof(float));\n",
    "\n",
    "    l.forward = forward_convolutional_layer;\n",
    "    l.backward = backward_convolutional_layer;\n",
    "    l.update = update_convolutional_layer;\n",
    "    \n",
    "//////////////////////////////////////////////////\n",
    "    /*EXPLAIN*/\n",
    "    \n",
    "    l.scales = calloc(n, sizeof(float));\n",
    "    l.scale_updates = calloc(n, sizeof(float));\n",
    "        for(i = 0; i < n; ++i){\n",
    "            l.scales[i] = 1;\n",
    "        }\n",
    "\n",
    "    l.mean = calloc(n, sizeof(float));\n",
    "    l.variance = calloc(n, sizeof(float));\n",
    "\n",
    "    l.mean_delta = calloc(n, sizeof(float));\n",
    "    l.variance_delta = calloc(n, sizeof(float));\n",
    "\n",
    "    l.rolling_mean = calloc(n, sizeof(float));\n",
    "    l.rolling_variance = calloc(n, sizeof(float));\n",
    "    l.x = calloc(l.batch*l.outputs, sizeof(float));\n",
    "    l.x_norm = calloc(l.batch*l.outputs, sizeof(float));\n",
    "   \n",
    "////////////////////////////////////////////////////////\n",
    "    NOT GOING OVER GPU SET UP\n",
    "///////////////////////////////////////////////////////\n",
    "\n",
    "    l.workspace_size = get_workspace_size(l);\n",
    "    l.activation = activation;\n",
    "\n",
    "    fprintf(stderr, \"conv  %5d %2d x%2d /%2d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", n, size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "\n",
    "    return l;\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn! Here are the functions integral to training our ConvNet:\n",
    "- forward_convolutional_layer = Applies convolution onto a given convolutional layer, \n",
    "\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT\n",
    "\n",
    "void forward_convolutional_layer(convolutional_layer l, network net)\n",
    "{\n",
    "    int i, j;\n",
    "\n",
    "    fill_cpu(l.outputs*l.batch, 0, l.output, 1);\n",
    "\n",
    "    if(l.xnor){\n",
    "        binarize_weights(l.weights, l.n, l.c/l.groups*l.size*l.size, l.binary_weights);\n",
    "        swap_binary(&l);\n",
    "        binarize_cpu(net.input, l.c*l.h*l.w*l.batch, l.binary_input);\n",
    "        net.input = l.binary_input;\n",
    "    }\n",
    "\n",
    "/////////////////////////////////////////////////////////////////////////////////////////\n",
    "    ///GIVEN THESE\n",
    "    int m = l.n/l.groups;               ///\n",
    "    int k = l.size*l.size*l.c/l.groups; ///\n",
    "    int n = l.out_w*l.out_h;            ///output area size\n",
    "    ////\n",
    "    for(i = 0; i < l.batch; ++i){\n",
    "        for(j = 0; j < l.groups; ++j){   //configure the memory placement of the pointers\n",
    "            float *a = l.weights + j*l.nweights/l.groups;\n",
    "            float *b = net.workspace;\n",
    "            float *c = l.output + (i*l.groups + j)*n*m;\n",
    "\n",
    "            im2col_cpu(net.input + (i*l.groups + j)*l.c/l.groups*l.h*l.w,  \n",
    "                l.c/l.groups, l.h, l.w, l.size, l.stride, l.pad, b);   /////GIVEN\n",
    "            gemm(0,0,m,n,k,1,a,k,b,n,1,c,n); // General Matrix multiplication ( TA, TB, M, N, K, ALPHA,A,lda, B, ldb,BETA,C,ldc);\n",
    "            //CAll this to test GEMM to show ppl void time_random_matrix(int TA, int TB, int m, int k, int n)\n",
    "        \n",
    "        }\n",
    "    }\n",
    "///////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    if(l.batch_normalize){\n",
    "        forward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        add_bias(l.output, l.biases, l.batch, l.n, l.out_h*l.out_w);\n",
    "    }\n",
    "\n",
    "    activate_array(l.output, l.outputs*l.batch, l.activation);\n",
    "    if(l.binary || l.xnor) swap_binary(&l);\n",
    "}\n",
    "//////////////////\n",
    "//////////////////\n",
    "///////poop///////\n",
    "//////////////////\n",
    "//////////////////\n",
    "//Backpropagation on a convolutional layer\n",
    "void backward_convolutional_layer(convolutional_layer l, network net)\n",
    "{\n",
    "    int i, j;\n",
    "    int m = l.n/l.groups;\n",
    "    int n = l.size*l.size*l.c/l.groups;\n",
    "    int k = l.out_w*l.out_h;\n",
    "\n",
    "    \n",
    "    gradient_array(l.output, l.outputs*l.batch, l.activation, l.delta); //gets rate of change \n",
    "\n",
    "    if(l.batch_normalize){\n",
    "        backward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        backward_bias(l.bias_updates, l.delta, l.batch, l.n, k);\n",
    "    }\n",
    "    \n",
    "    \n",
    "////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "    for(i = 0; i < l.batch; ++i){\n",
    "        for(j = 0; j < l.groups; ++j){\n",
    "            float *a = l.delta + (i*l.groups + j)*m*k;   //updates each image in batch, group for group.\n",
    "            float *b = net.workspace;\n",
    "            float *c = l.weight_updates + j*l.nweights/l.groups;\n",
    "\n",
    "            float *im = net.input+(i*l.groups + j)*l.c/l.groups*l.h*l.w;\n",
    "\n",
    "            im2col_cpu(im, l.c/l.groups, l.h, l.w, \n",
    "                    l.size, l.stride, l.pad, b);\n",
    "            gemm(0,1,m,n,k,1,a,k,b,k,1,c,n);\n",
    "\n",
    "            if(net.delta){\n",
    "                a = l.weights + j*l.nweights/l.groups;\n",
    "                b = l.delta + (i*l.groups + j)*m*k;\n",
    "                c = net.workspace;\n",
    "\n",
    "                gemm(1,0,n,k,m,1,a,n,b,k,0,c,k); //apply the general matrix mult\n",
    "\n",
    "                col2im_cpu(net.workspace, l.c/l.groups, l.h, l.w, l.size, l.stride, \n",
    "                    l.pad, net.delta + (i*l.groups + j)*l.c/l.groups*l.h*l.w);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "//////////////////////////////////////////////////////////////////////////////////////////\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image get_maxpool_delta(maxpool_layer l)\n",
    "{\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "    return float_to_image(w,h,c,l.delta);\n",
    "}\n",
    "\n",
    "maxpool_layer make_maxpool_layer(int batch, int h, int w, int c, int size, int stride, int padding)\n",
    "{\n",
    "    maxpool_layer l = {0};\n",
    "    l.type = MAXPOOL;\n",
    "    l.batch = batch;\n",
    "    l.h = h;\n",
    "    l.w = w;\n",
    "    l.c = c;\n",
    "    l.pad = padding;\n",
    "    l.out_w = (w + 2*padding)/stride;\n",
    "    l.out_h = (h + 2*padding)/stride;\n",
    "    l.out_c = c;\n",
    "    l.outputs = l.out_h * l.out_w * l.out_c;\n",
    "    l.inputs = h*w*c;\n",
    "    l.size = size;\n",
    "    l.stride = stride;\n",
    "    int output_size = l.out_h * l.out_w * l.out_c * batch;\n",
    "    l.indexes = calloc(output_size, sizeof(int));\n",
    "    l.output =  calloc(output_size, sizeof(float));\n",
    "    l.delta =   calloc(output_size, sizeof(float));\n",
    "    l.forward = forward_maxpool_layer;\n",
    "    l.backward = backward_maxpool_layer;\n",
    "    #ifdef GPU\n",
    "    l.forward_gpu = forward_maxpool_layer_gpu;\n",
    "    l.backward_gpu = backward_maxpool_layer_gpu;\n",
    "    l.indexes_gpu = cuda_make_int_array(0, output_size);\n",
    "    l.output_gpu  = cuda_make_array(l.output, output_size);\n",
    "    l.delta_gpu   = cuda_make_array(l.delta, output_size);\n",
    "    #endif\n",
    "    fprintf(stderr, \"max          %d x %d / %d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "    return l;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T06:21:50.987595Z",
     "start_time": "2018-03-07T06:21:50.952433Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-bb0607d5506f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-bb0607d5506f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    void forward_maxpool_layer(const maxpool_layer l, network net)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STUDENT\n",
    "\n",
    "void forward_maxpool_layer(const maxpool_layer l, network net)\n",
    "{\n",
    "    int b,i,j,k,m,n;\n",
    "    int w_offset = -l.pad;\n",
    "    int h_offset = -l.pad;\n",
    "\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "////////////////////////////////////////////////////////////\n",
    "    for(b = 0; b < l.batch; ++b){\n",
    "        for(k = 0; k < c; ++k){\n",
    "            for(i = 0; i < h; ++i){\n",
    "                for(j = 0; j < w; ++j){\n",
    "                    int out_index = j + w*(i + h*(k + c*b));\n",
    "                    \n",
    "                    //\n",
    "                    float max = -FLT_MAX;\n",
    "                    int max_i = -1;\n",
    "                    for(n = 0; n < l.size; ++n){\n",
    "                        for(m = 0; m < l.size; ++m){\n",
    "                            int cur_h = h_offset + i*l.stride + n;\n",
    "                            int cur_w = w_offset + j*l.stride + m;\n",
    "                            int index = cur_w + l.w*(cur_h + l.h*(k + b*l.c));\n",
    "                            int valid = (cur_h >= 0 && cur_h < l.h &&\n",
    "                                         cur_w >= 0 && cur_w < l.w);\n",
    "                            float val = (valid != 0) ? net.input[index] : -FLT_MAX;\n",
    "                            max_i = (val > max) ? index : max_i;\n",
    "                            max   = (val > max) ? val   : max;\n",
    "                        }\n",
    "                    }\n",
    "                    //\n",
    "                    \n",
    "                    l.output[out_index] = max;\n",
    "                    l.indexes[out_index] = max_i;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "////////////////////////////////////////////////////////////////\n",
    "}\n",
    "\n",
    "void backward_maxpool_layer(const maxpool_layer l, network net)\n",
    "{\n",
    "    int i;\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "    for(i = 0; i < h*w*c*l.batch; ++i){\n",
    "        int index = l.indexes[i];\n",
    "        net.delta[index] += l.delta[i];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T20:44:07.240842Z",
     "start_time": "2018-03-07T20:44:07.234969Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c6eaf35ccd9c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-c6eaf35ccd9c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    TODO:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TODO:\n",
    "    add steps how to build darknet here\n",
    "    give example of how to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "github": "thedibaccle",
    "name": "Richard DiBacco"
   }
  ],
  "hide_input": false,
  "kernelspec": {
   "display_name": "C",
   "language": "c",
   "name": "c"
  },
  "language_info": {
   "file_extension": ".c",
   "mimetype": "text/plain",
   "name": "c"
  },
  "livereveal": {
   "footer": "<footer id=\"slide_foot\">\n  <div  id=\"slide_foot-brand\">\n    <span class=\"ucfsigai-brand\"></span>\n  </div>\n  <div  id=\"slide_foot-unit\">\n    <span class=\"text-gold\"> U2: </span>&nbsp;<span class=\"text-white\"> Convolutional Neural Networks </span>\n  </div>\n  <a    id=\"slide_foot-attend\" href=\"https://goo.gl/\">\n      <span class=\"text-white\"> https://goo.gl/ </span>\n  </a>\n  <div  id=\"slide_foot-date\">\n    <span class=\"text-white\"> Feb 22, 2018 </span>\n  </div>\n</footer>\n",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
