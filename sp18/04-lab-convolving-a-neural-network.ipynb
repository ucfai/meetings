{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T03:50:49.812901Z",
     "start_time": "2018-03-07T03:50:49.808255Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, SVG, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T06:30:33.368227Z",
     "start_time": "2018-03-07T06:30:33.360161Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "if \"../data/darknet\" not in sys.path:\n",
    "    sys.path.insert(0, '/sp18/data/darknet')\n",
    "\n",
    "# Neural Nets SVG dims, this is for the NN forward-pass walkthrough.\n",
    "# SVG's default size is 732x518 ~ which is the (width * 0.7076502732)\n",
    "NN_SVG_W = 732\n",
    "NN_SVG_H = math.ceil(NN_SVG_W * 0.7076502732) + 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "TODO: FIND ALL HEADERS U NEED TO INCLUDE!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolving a Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time object detection and classification with YOLO\n",
    "\n",
    "**What you'll learn:** \n",
    "- How a Convolutional Neural Network is implemented in a real world application\n",
    "- How to build convolutional and (max)pooling layers in C\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: Backpropagation in ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct layer{\n",
    "    LAYER_TYPE type;\n",
    "    ACTIVATION activation;\n",
    "    COST_TYPE cost_type;\n",
    "    void (*forward)   (struct layer, struct network);\n",
    "    void (*backward)  (struct layer, struct network);\n",
    "    void (*update)    (struct layer, update_args);\n",
    "    void (*forward_gpu)   (struct layer, struct network);\n",
    "    void (*backward_gpu)  (struct layer, struct network);\n",
    "    void (*update_gpu)    (struct layer, update_args);\n",
    "    int batch_normalize;\n",
    "    int shortcut;\n",
    "    int batch;\n",
    "    int forced;\n",
    "    int flipped;\n",
    "    int inputs;\n",
    "    int outputs;\n",
    "    int nweights;\n",
    "    int nbiases;\n",
    "    int extra;\n",
    "    int truths;\n",
    "    int h,w,c;\n",
    "    int out_h, out_w, out_c;\n",
    "    int n;\n",
    "    int max_boxes;\n",
    "    int groups;\n",
    "    int size;\n",
    "    int side;\n",
    "    int stride;\n",
    "    int reverse;\n",
    "    int flatten;\n",
    "    int spatial;\n",
    "    int pad;\n",
    "    int sqrt;\n",
    "    int flip;\n",
    "    int index;\n",
    "    int binary;\n",
    "    int xnor;\n",
    "    int steps;\n",
    "    int hidden;\n",
    "    int truth;\n",
    "    float smooth;\n",
    "    float dot;\n",
    "    float angle;\n",
    "    float jitter;\n",
    "    float saturation;\n",
    "    float exposure;\n",
    "    float shift;\n",
    "    float ratio;\n",
    "    float learning_rate_scale;\n",
    "    int softmax;\n",
    "    int classes;\n",
    "    int coords;\n",
    "    int background;\n",
    "    int rescore;\n",
    "    int objectness;\n",
    "    int does_cost;\n",
    "    int joint;\n",
    "    int noadjust;\n",
    "    int reorg;\n",
    "    int log;\n",
    "    int tanh;\n",
    "\n",
    "    float alpha;\n",
    "    float beta;\n",
    "    float kappa;\n",
    "\n",
    "    float coord_scale;\n",
    "    float object_scale;\n",
    "    float noobject_scale;\n",
    "    float mask_scale;\n",
    "    float class_scale;\n",
    "    int bias_match;\n",
    "    int random;\n",
    "    float thresh;\n",
    "    int classfix;\n",
    "    int absolute;\n",
    "\n",
    "    int onlyforward;\n",
    "    int stopbackward;\n",
    "    int dontload;\n",
    "    int dontloadscales;\n",
    "\n",
    "    float temperature;\n",
    "    float probability;\n",
    "    float scale;\n",
    "\n",
    "    char  * cweights;\n",
    "    int   * indexes;\n",
    "    int   * input_layers;\n",
    "    int   * input_sizes;\n",
    "    int   * map;\n",
    "    float * rand;\n",
    "    float * cost;\n",
    "    float * state;\n",
    "    float * prev_state;\n",
    "    float * forgot_state;\n",
    "    float * forgot_delta;\n",
    "    float * state_delta;\n",
    "    float * combine_cpu;\n",
    "    float * combine_delta_cpu;\n",
    "\n",
    "    float * concat;\n",
    "    float * concat_delta;\n",
    "\n",
    "    float * binary_weights;\n",
    "\n",
    "    float * biases;\n",
    "    float * bias_updates;\n",
    "\n",
    "    float * scales;\n",
    "    float * scale_updates;\n",
    "\n",
    "    float * weights;\n",
    "    float * weight_updates;\n",
    "\n",
    "    float * delta;\n",
    "    float * output;\n",
    "    float * squared;\n",
    "    float * norms;\n",
    "\n",
    "    float * spatial_mean;\n",
    "    float * mean;\n",
    "    float * variance;\n",
    "\n",
    "    float * mean_delta;\n",
    "    float * variance_delta;\n",
    "\n",
    "    float * rolling_mean;\n",
    "    float * rolling_variance;\n",
    "\n",
    "    float * x;\n",
    "    float * x_norm;\n",
    "\n",
    "    float * m;\n",
    "    float * v;\n",
    "    \n",
    "    float * bias_m;\n",
    "    float * bias_v;\n",
    "    float * scale_m;\n",
    "    float * scale_v;\n",
    "\n",
    "\n",
    "    float *z_cpu;\n",
    "    float *r_cpu;\n",
    "    float *h_cpu;\n",
    "    float * prev_state_cpu;\n",
    "\n",
    "    float *temp_cpu;\n",
    "    float *temp2_cpu;\n",
    "    float *temp3_cpu;\n",
    "\n",
    "    float *dh_cpu;\n",
    "    float *hh_cpu;\n",
    "    float *prev_cell_cpu;\n",
    "    float *cell_cpu;\n",
    "    float *f_cpu;\n",
    "    float *i_cpu;\n",
    "    float *g_cpu;\n",
    "    float *o_cpu;\n",
    "    float *c_cpu;\n",
    "    float *dc_cpu; \n",
    "\n",
    "    float * binary_input;\n",
    "\n",
    "    struct layer *input_layer;\n",
    "    struct layer *self_layer;\n",
    "    struct layer *output_layer;\n",
    "\n",
    "    struct layer *reset_layer;\n",
    "    struct layer *update_layer;\n",
    "    struct layer *state_layer;\n",
    "\n",
    "    struct layer *input_gate_layer;\n",
    "    struct layer *state_gate_layer;\n",
    "    struct layer *input_save_layer;\n",
    "    struct layer *state_save_layer;\n",
    "    struct layer *input_state_layer;\n",
    "    struct layer *state_state_layer;\n",
    "\n",
    "    struct layer *input_z_layer;\n",
    "    struct layer *state_z_layer;\n",
    "\n",
    "    struct layer *input_r_layer;\n",
    "    struct layer *state_r_layer;\n",
    "\n",
    "    struct layer *input_h_layer;\n",
    "    struct layer *state_h_layer;\n",
    "\t\n",
    "    struct layer *wz;\n",
    "    struct layer *uz;\n",
    "    struct layer *wr;\n",
    "    struct layer *ur;\n",
    "    struct layer *wh;\n",
    "    struct layer *uh;\n",
    "    struct layer *uo;\n",
    "    struct layer *wo;\n",
    "    struct layer *uf;\n",
    "    struct layer *wf;\n",
    "    struct layer *ui;\n",
    "    struct layer *wi;\n",
    "    struct layer *ug;\n",
    "    struct layer *wg;\n",
    "\n",
    "    tree *softmax_tree;\n",
    "\n",
    "    size_t workspace_size;\n",
    "\n",
    "#ifdef GPU\n",
    "    int *indexes_gpu;\n",
    "\n",
    "    float *z_gpu;\n",
    "    float *r_gpu;\n",
    "    float *h_gpu;\n",
    "\n",
    "    float *temp_gpu;\n",
    "    float *temp2_gpu;\n",
    "    float *temp3_gpu;\n",
    "\n",
    "    float *dh_gpu;\n",
    "    float *hh_gpu;\n",
    "    float *prev_cell_gpu;\n",
    "    float *cell_gpu;\n",
    "    float *f_gpu;\n",
    "    float *i_gpu;\n",
    "    float *g_gpu;\n",
    "    float *o_gpu;\n",
    "    float *c_gpu;\n",
    "    float *dc_gpu; \n",
    "\n",
    "    float *m_gpu;\n",
    "    float *v_gpu;\n",
    "    float *bias_m_gpu;\n",
    "    float *scale_m_gpu;\n",
    "    float *bias_v_gpu;\n",
    "    float *scale_v_gpu;\n",
    "\n",
    "    float * combine_gpu;\n",
    "    float * combine_delta_gpu;\n",
    "\n",
    "    float * prev_state_gpu;\n",
    "    float * forgot_state_gpu;\n",
    "    float * forgot_delta_gpu;\n",
    "    float * state_gpu;\n",
    "    float * state_delta_gpu;\n",
    "    float * gate_gpu;\n",
    "    float * gate_delta_gpu;\n",
    "    float * save_gpu;\n",
    "    float * save_delta_gpu;\n",
    "    float * concat_gpu;\n",
    "    float * concat_delta_gpu;\n",
    "\n",
    "    float * binary_input_gpu;\n",
    "    float * binary_weights_gpu;\n",
    "\n",
    "    float * mean_gpu;\n",
    "    float * variance_gpu;\n",
    "\n",
    "    float * rolling_mean_gpu;\n",
    "    float * rolling_variance_gpu;\n",
    "\n",
    "    float * variance_delta_gpu;\n",
    "    float * mean_delta_gpu;\n",
    "\n",
    "    float * x_gpu;\n",
    "    float * x_norm_gpu;\n",
    "    float * weights_gpu;\n",
    "    float * weight_updates_gpu;\n",
    "    float * weight_change_gpu;\n",
    "\n",
    "    float * biases_gpu;\n",
    "    float * bias_updates_gpu;\n",
    "    float * bias_change_gpu;\n",
    "\n",
    "    float * scales_gpu;\n",
    "    float * scale_updates_gpu;\n",
    "    float * scale_change_gpu;\n",
    "\n",
    "    float * output_gpu;\n",
    "    float * delta_gpu;\n",
    "    float * rand_gpu;\n",
    "    float * squared_gpu;\n",
    "    float * norms_gpu;\n",
    "#ifdef CUDNN\n",
    "    cudnnTensorDescriptor_t srcTensorDesc, dstTensorDesc;\n",
    "    cudnnTensorDescriptor_t dsrcTensorDesc, ddstTensorDesc;\n",
    "    cudnnTensorDescriptor_t normTensorDesc;\n",
    "    cudnnFilterDescriptor_t weightDesc;\n",
    "    cudnnFilterDescriptor_t dweightDesc;\n",
    "    cudnnConvolutionDescriptor_t convDesc;\n",
    "    cudnnConvolutionFwdAlgo_t fw_algo;\n",
    "    cudnnConvolutionBwdDataAlgo_t bd_algo;\n",
    "    cudnnConvolutionBwdFilterAlgo_t bf_algo;\n",
    "#endif\n",
    "#endif\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Breaking down the ConvNet pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ConvNet is a series of Convolutional and pooling layers appended to a (usually) fully connected neural network (or ANN.) These layers are needed in order to maintain spatial relations between pixels in an image, something that ANNs are unable to do. Our last workshop went over how to program an ANN from scratch. We now want to show how we can add these additional layers to our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/images/CNN_pipeline.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each convolutional layer, we must denote the dimensions of the input. Our inputs will strictly be images, so we have width **w** and height **h** of the input matrix. Since we read the data in as one big array, we partition the array into equal sizes. **c** is the count, as in, how many different matrices we want to be reading in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "Have a evaluation function that checks to see if the function they wrote is functional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*\n",
    "void test_convolutional_layer()\n",
    "{\n",
    "    convolutional_layer l = make_convolutional_layer(1, 5, 5, 3, 2, 5, 2, 1, RELU, 1, 0, 0, 0);\n",
    "    l.batch_normalize = 1;\n",
    "    float data[] = {1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        1,1,1,1,1,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        2,2,2,2,2,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3,\n",
    "        3,3,3,3,3};\n",
    "    //net.input = data;\n",
    "    //forward_convolutional_layer(l);\n",
    "}\n",
    "*/\n",
    "\n",
    "convolutional_layer make_convolutional_layer(int batch, int h, int w, int c, int n, int groups, int size, int stride, int padding, ACTIVATION activation, int batch_normalize, int binary, int xnor, int adam)\n",
    "{\n",
    "    int i;\n",
    "    convolutional_layer l = {0};\n",
    "    l.type = CONVOLUTIONAL;\n",
    "\n",
    "    l.groups = groups;\n",
    "    l.h = h;\n",
    "    l.w = w;\n",
    "    l.c = c;\n",
    "    l.n = n;\n",
    "    l.binary = binary;\n",
    "    l.xnor = xnor;\n",
    "    l.batch = batch;\n",
    "    l.stride = stride;\n",
    "    l.size = size;\n",
    "    l.pad = padding;\n",
    "    l.batch_normalize = batch_normalize;\n",
    "\n",
    "    l.weights = calloc(c/groups*n*size*size, sizeof(float));\n",
    "    l.weight_updates = calloc(c/groups*n*size*size, sizeof(float));\n",
    "\n",
    "    l.biases = calloc(n, sizeof(float));\n",
    "    l.bias_updates = calloc(n, sizeof(float));\n",
    "\n",
    "    l.nweights = c/groups*n*size*size;\n",
    "    l.nbiases = n;\n",
    "\n",
    "    // float scale = 1./sqrt(size*size*c);\n",
    "    float scale = sqrt(2./(size*size*c/l.groups));\n",
    "    //scale = .02;\n",
    "    //for(i = 0; i < c*n*size*size; ++i) l.weights[i] = scale*rand_uniform(-1, 1);\n",
    "    for(i = 0; i < l.nweights; ++i) l.weights[i] = scale*rand_normal();\n",
    "    int out_w = convolutional_out_width(l);\n",
    "    int out_h = convolutional_out_height(l);\n",
    "    l.out_h = out_h;\n",
    "    l.out_w = out_w;\n",
    "    l.out_c = n;\n",
    "    l.outputs = l.out_h * l.out_w * l.out_c;\n",
    "    l.inputs = l.w * l.h * l.c;\n",
    "\n",
    "    l.output = calloc(l.batch*l.outputs, sizeof(float));\n",
    "    l.delta  = calloc(l.batch*l.outputs, sizeof(float));\n",
    "\n",
    "    l.forward = forward_convolutional_layer;\n",
    "    l.backward = backward_convolutional_layer;\n",
    "    l.update = update_convolutional_layer;\n",
    "    if(binary){\n",
    "        l.binary_weights = calloc(l.nweights, sizeof(float));\n",
    "        l.cweights = calloc(l.nweights, sizeof(char));\n",
    "        l.scales = calloc(n, sizeof(float));\n",
    "    }\n",
    "    if(xnor){\n",
    "        l.binary_weights = calloc(l.nweights, sizeof(float));\n",
    "        l.binary_input = calloc(l.inputs*l.batch, sizeof(float));\n",
    "    }\n",
    "\n",
    "    if(batch_normalize){\n",
    "        l.scales = calloc(n, sizeof(float));\n",
    "        l.scale_updates = calloc(n, sizeof(float));\n",
    "        for(i = 0; i < n; ++i){\n",
    "            l.scales[i] = 1;\n",
    "        }\n",
    "\n",
    "        l.mean = calloc(n, sizeof(float));\n",
    "        l.variance = calloc(n, sizeof(float));\n",
    "\n",
    "        l.mean_delta = calloc(n, sizeof(float));\n",
    "        l.variance_delta = calloc(n, sizeof(float));\n",
    "\n",
    "        l.rolling_mean = calloc(n, sizeof(float));\n",
    "        l.rolling_variance = calloc(n, sizeof(float));\n",
    "        l.x = calloc(l.batch*l.outputs, sizeof(float));\n",
    "        l.x_norm = calloc(l.batch*l.outputs, sizeof(float));\n",
    "    }\n",
    "    if(adam){\n",
    "        l.m = calloc(l.nweights, sizeof(float));\n",
    "        l.v = calloc(l.nweights, sizeof(float));\n",
    "        l.bias_m = calloc(n, sizeof(float));\n",
    "        l.scale_m = calloc(n, sizeof(float));\n",
    "        l.bias_v = calloc(n, sizeof(float));\n",
    "        l.scale_v = calloc(n, sizeof(float));\n",
    "    }\n",
    "\n",
    "#ifdef GPU\n",
    "    l.forward_gpu = forward_convolutional_layer_gpu;\n",
    "    l.backward_gpu = backward_convolutional_layer_gpu;\n",
    "    l.update_gpu = update_convolutional_layer_gpu;\n",
    "\n",
    "    if(gpu_index >= 0){\n",
    "        if (adam) {\n",
    "            l.m_gpu = cuda_make_array(l.m, l.nweights);\n",
    "            l.v_gpu = cuda_make_array(l.v, l.nweights);\n",
    "            l.bias_m_gpu = cuda_make_array(l.bias_m, n);\n",
    "            l.bias_v_gpu = cuda_make_array(l.bias_v, n);\n",
    "            l.scale_m_gpu = cuda_make_array(l.scale_m, n);\n",
    "            l.scale_v_gpu = cuda_make_array(l.scale_v, n);\n",
    "        }\n",
    "\n",
    "        l.weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
    "        l.weight_updates_gpu = cuda_make_array(l.weight_updates, l.nweights);\n",
    "\n",
    "        l.biases_gpu = cuda_make_array(l.biases, n);\n",
    "        l.bias_updates_gpu = cuda_make_array(l.bias_updates, n);\n",
    "\n",
    "        l.delta_gpu = cuda_make_array(l.delta, l.batch*out_h*out_w*n);\n",
    "        l.output_gpu = cuda_make_array(l.output, l.batch*out_h*out_w*n);\n",
    "\n",
    "        if(binary){\n",
    "            l.binary_weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
    "        }\n",
    "        if(xnor){\n",
    "            l.binary_weights_gpu = cuda_make_array(l.weights, l.nweights);\n",
    "            l.binary_input_gpu = cuda_make_array(0, l.inputs*l.batch);\n",
    "        }\n",
    "\n",
    "        if(batch_normalize){\n",
    "            l.mean_gpu = cuda_make_array(l.mean, n);\n",
    "            l.variance_gpu = cuda_make_array(l.variance, n);\n",
    "\n",
    "            l.rolling_mean_gpu = cuda_make_array(l.mean, n);\n",
    "            l.rolling_variance_gpu = cuda_make_array(l.variance, n);\n",
    "\n",
    "            l.mean_delta_gpu = cuda_make_array(l.mean, n);\n",
    "            l.variance_delta_gpu = cuda_make_array(l.variance, n);\n",
    "\n",
    "            l.scales_gpu = cuda_make_array(l.scales, n);\n",
    "            l.scale_updates_gpu = cuda_make_array(l.scale_updates, n);\n",
    "\n",
    "            l.x_gpu = cuda_make_array(l.output, l.batch*out_h*out_w*n);\n",
    "            l.x_norm_gpu = cuda_make_array(l.output, l.batch*out_h*out_w*n);\n",
    "        }\n",
    "#ifdef CUDNN\n",
    "        cudnnCreateTensorDescriptor(&l.normTensorDesc);\n",
    "        cudnnCreateTensorDescriptor(&l.srcTensorDesc);\n",
    "        cudnnCreateTensorDescriptor(&l.dstTensorDesc);\n",
    "        cudnnCreateFilterDescriptor(&l.weightDesc);\n",
    "        cudnnCreateTensorDescriptor(&l.dsrcTensorDesc);\n",
    "        cudnnCreateTensorDescriptor(&l.ddstTensorDesc);\n",
    "        cudnnCreateFilterDescriptor(&l.dweightDesc);\n",
    "        cudnnCreateConvolutionDescriptor(&l.convDesc);\n",
    "        cudnn_convolutional_setup(&l);\n",
    "#endif\n",
    "    }\n",
    "#endif\n",
    "    l.workspace_size = get_workspace_size(l);\n",
    "    l.activation = activation;\n",
    "\n",
    "    fprintf(stderr, \"conv  %5d %2d x%2d /%2d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", n, size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "\n",
    "    return l;\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDENT\n",
    "\n",
    "void forward_convolutional_layer(convolutional_layer l, network net)\n",
    "{\n",
    "    int i, j;\n",
    "\n",
    "    fill_cpu(l.outputs*l.batch, 0, l.output, 1);\n",
    "\n",
    "    if(l.xnor){\n",
    "        binarize_weights(l.weights, l.n, l.c/l.groups*l.size*l.size, l.binary_weights);\n",
    "        swap_binary(&l);\n",
    "        binarize_cpu(net.input, l.c*l.h*l.w*l.batch, l.binary_input);\n",
    "        net.input = l.binary_input;\n",
    "    }\n",
    "\n",
    "    int m = l.n/l.groups;\n",
    "    int k = l.size*l.size*l.c/l.groups;\n",
    "    int n = l.out_w*l.out_h;\n",
    "    for(i = 0; i < l.batch; ++i){\n",
    "        for(j = 0; j < l.groups; ++j){\n",
    "            float *a = l.weights + j*l.nweights/l.groups;\n",
    "            float *b = net.workspace;\n",
    "            float *c = l.output + (i*l.groups + j)*n*m;\n",
    "\n",
    "            im2col_cpu(net.input + (i*l.groups + j)*l.c/l.groups*l.h*l.w,\n",
    "                l.c/l.groups, l.h, l.w, l.size, l.stride, l.pad, b);\n",
    "            gemm(0,0,m,n,k,1,a,k,b,n,1,c,n); // Generall Matrix multiplication ( TA, TB, M, N, K, ALPHA,A,lda, B, ldb,BETA,C,ldc);\n",
    "            //CAll this to test GEMM to show ppl void time_random_matrix(int TA, int TB, int m, int k, int n)\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "    if(l.batch_normalize){\n",
    "        forward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        add_bias(l.output, l.biases, l.batch, l.n, l.out_h*l.out_w);\n",
    "    }\n",
    "\n",
    "    activate_array(l.output, l.outputs*l.batch, l.activation);\n",
    "    if(l.binary || l.xnor) swap_binary(&l);\n",
    "}\n",
    "\n",
    "//Backpropagation on a convolutional layer\n",
    "void backward_convolutional_layer(convolutional_layer l, network net)\n",
    "{\n",
    "    int i, j;\n",
    "    int m = l.n/l.groups;\n",
    "    int n = l.size*l.size*l.c/l.groups;\n",
    "    int k = l.out_w*l.out_h;\n",
    "\n",
    "    gradient_array(l.output, l.outputs*l.batch, l.activation, l.delta); //gets rate of change \n",
    "\n",
    "    if(l.batch_normalize){\n",
    "        backward_batchnorm_layer(l, net);\n",
    "    } else {\n",
    "        backward_bias(l.bias_updates, l.delta, l.batch, l.n, k);\n",
    "    }\n",
    "\n",
    "    for(i = 0; i < l.batch; ++i){\n",
    "        for(j = 0; j < l.groups; ++j){\n",
    "            float *a = l.delta + (i*l.groups + j)*m*k;   //updates each image in batch, group for group.\n",
    "            float *b = net.workspace;\n",
    "            float *c = l.weight_updates + j*l.nweights/l.groups;\n",
    "\n",
    "            float *im = net.input+(i*l.groups + j)*l.c/l.groups*l.h*l.w;\n",
    "\n",
    "            im2col_cpu(im, l.c/l.groups, l.h, l.w, \n",
    "                    l.size, l.stride, l.pad, b);\n",
    "            gemm(0,1,m,n,k,1,a,k,b,k,1,c,n);\n",
    "\n",
    "            if(net.delta){\n",
    "                a = l.weights + j*l.nweights/l.groups;\n",
    "                b = l.delta + (i*l.groups + j)*m*k;\n",
    "                c = net.workspace;\n",
    "\n",
    "                gemm(1,0,n,k,m,1,a,n,b,k,0,c,k); //apply the general matrix mult\n",
    "\n",
    "                col2im_cpu(net.workspace, l.c/l.groups, l.h, l.w, l.size, l.stride, \n",
    "                    l.pad, net.delta + (i*l.groups + j)*l.c/l.groups*l.h*l.w);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void update_convolutional_layer(convolutional_layer l, update_args a)  //update layer for next training iteration\n",
    "{\n",
    "    float learning_rate = a.learning_rate*l.learning_rate_scale;\n",
    "    float momentum = a.momentum;\n",
    "    float decay = a.decay;\n",
    "    int batch = a.batch;\n",
    "\n",
    "    axpy_cpu(l.n, learning_rate/batch, l.bias_updates, 1, l.biases, 1);\n",
    "    scal_cpu(l.n, momentum, l.bias_updates, 1);\n",
    "\n",
    "    if(l.scales){\n",
    "        axpy_cpu(l.n, learning_rate/batch, l.scale_updates, 1, l.scales, 1);\n",
    "        scal_cpu(l.n, momentum, l.scale_updates, 1);\n",
    "    }\n",
    "\n",
    "    axpy_cpu(l.nweights, -decay*batch, l.weights, 1, l.weight_updates, 1);\n",
    "    axpy_cpu(l.nweights, learning_rate/batch, l.weight_updates, 1, l.weights, 1);\n",
    "    scal_cpu(l.nweights, momentum, l.weight_updates, 1);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image get_maxpool_delta(maxpool_layer l)\n",
    "{\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "    return float_to_image(w,h,c,l.delta);\n",
    "}\n",
    "\n",
    "maxpool_layer make_maxpool_layer(int batch, int h, int w, int c, int size, int stride, int padding)\n",
    "{\n",
    "    maxpool_layer l = {0};\n",
    "    l.type = MAXPOOL;\n",
    "    l.batch = batch;\n",
    "    l.h = h;\n",
    "    l.w = w;\n",
    "    l.c = c;\n",
    "    l.pad = padding;\n",
    "    l.out_w = (w + 2*padding)/stride;\n",
    "    l.out_h = (h + 2*padding)/stride;\n",
    "    l.out_c = c;\n",
    "    l.outputs = l.out_h * l.out_w * l.out_c;\n",
    "    l.inputs = h*w*c;\n",
    "    l.size = size;\n",
    "    l.stride = stride;\n",
    "    int output_size = l.out_h * l.out_w * l.out_c * batch;\n",
    "    l.indexes = calloc(output_size, sizeof(int));\n",
    "    l.output =  calloc(output_size, sizeof(float));\n",
    "    l.delta =   calloc(output_size, sizeof(float));\n",
    "    l.forward = forward_maxpool_layer;\n",
    "    l.backward = backward_maxpool_layer;\n",
    "    #ifdef GPU\n",
    "    l.forward_gpu = forward_maxpool_layer_gpu;\n",
    "    l.backward_gpu = backward_maxpool_layer_gpu;\n",
    "    l.indexes_gpu = cuda_make_int_array(0, output_size);\n",
    "    l.output_gpu  = cuda_make_array(l.output, output_size);\n",
    "    l.delta_gpu   = cuda_make_array(l.delta, output_size);\n",
    "    #endif\n",
    "    fprintf(stderr, \"max          %d x %d / %d  %4d x%4d x%4d   ->  %4d x%4d x%4d\\n\", size, size, stride, w, h, c, l.out_w, l.out_h, l.out_c);\n",
    "    return l;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T06:21:50.987595Z",
     "start_time": "2018-03-07T06:21:50.952433Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-bb0607d5506f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-bb0607d5506f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    void forward_maxpool_layer(const maxpool_layer l, network net)\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "STUDENT\n",
    "\n",
    "void forward_maxpool_layer(const maxpool_layer l, network net)\n",
    "{\n",
    "    int b,i,j,k,m,n;\n",
    "    int w_offset = -l.pad;\n",
    "    int h_offset = -l.pad;\n",
    "\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "\n",
    "    for(b = 0; b < l.batch; ++b){\n",
    "        for(k = 0; k < c; ++k){\n",
    "            for(i = 0; i < h; ++i){\n",
    "                for(j = 0; j < w; ++j){\n",
    "                    int out_index = j + w*(i + h*(k + c*b));\n",
    "                    float max = -FLT_MAX;\n",
    "                    int max_i = -1;\n",
    "                    for(n = 0; n < l.size; ++n){\n",
    "                        for(m = 0; m < l.size; ++m){\n",
    "                            int cur_h = h_offset + i*l.stride + n;\n",
    "                            int cur_w = w_offset + j*l.stride + m;\n",
    "                            int index = cur_w + l.w*(cur_h + l.h*(k + b*l.c));\n",
    "                            int valid = (cur_h >= 0 && cur_h < l.h &&\n",
    "                                         cur_w >= 0 && cur_w < l.w);\n",
    "                            float val = (valid != 0) ? net.input[index] : -FLT_MAX;\n",
    "                            max_i = (val > max) ? index : max_i;\n",
    "                            max   = (val > max) ? val   : max;\n",
    "                        }\n",
    "                    }\n",
    "                    l.output[out_index] = max;\n",
    "                    l.indexes[out_index] = max_i;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void backward_maxpool_layer(const maxpool_layer l, network net)\n",
    "{\n",
    "    int i;\n",
    "    int h = l.out_h;\n",
    "    int w = l.out_w;\n",
    "    int c = l.c;\n",
    "    for(i = 0; i < h*w*c*l.batch; ++i){\n",
    "        int index = l.indexes[i];\n",
    "        net.delta[index] += l.delta[i];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T06:32:32.932637Z",
     "start_time": "2018-03-07T06:32:32.926585Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'subprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5fc3e0407d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/darknet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'subprocess'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.subprocess(\"../data/darknet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "github": "thedibaccle",
    "name": "Richard DiBacco"
   }
  ],
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "footer": "<footer id=\"slide_foot\">\n  <div  id=\"slide_foot-brand\">\n    <span class=\"ucfsigai-brand\"></span>\n  </div>\n  <div  id=\"slide_foot-unit\">\n    <span class=\"text-gold\"> U2: </span>&nbsp;<span class=\"text-white\"> Convolutional Neural Networks </span>\n  </div>\n  <a    id=\"slide_foot-attend\" href=\"https://goo.gl/\">\n      <span class=\"text-white\"> https://goo.gl/ </span>\n  </a>\n  <div  id=\"slide_foot-date\">\n    <span class=\"text-white\"> Feb 22, 2018 </span>\n  </div>\n</footer>\n",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
